{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS271P_Logistic_Regression.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ml0R0aeL9oV0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ef21cf-ad7d-4848-cc29-aac51827cb4f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwPOmNi79xt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfbe231-d873-4838-a1c4-6ac9981fe79e"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I0g6ndW9zrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a5c9a8-b812-4acf-d2ec-492c91a74929"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/CS271P_project"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/CS271P_project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doBcBvBZ91Dy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8215231e-4199-49f9-9d43-0d50383796b2"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1m_tweets.csv  final_dataset.csv  glove\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4GbOH6o99Gr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c00e7f0-2e67-40bd-fb30-2390fa8bc851"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from wordcloud import WordCloud\n",
        "from textblob import TextBlob, Word\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tweets = pd.read_csv('final_dataset.csv', encoding=\"utf-8\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKED456o-Phc"
      },
      "source": [
        "def remove_unnecessary_data_from(tweets):\n",
        "    refined_tweets = []\n",
        "    for tweet in tweets:\n",
        "        tweet = str(tweet)\n",
        "        # Converting to lowercase\n",
        "        tweet = tweet.lower()\n",
        "        # Remove unnecessary things like mentions and hashtags\n",
        "        tweet = re.sub('@[^ ]+|#[^ ]+', '', tweet)\n",
        "        # Remove punctuation\n",
        "        tweet = tweet.replace('[^A-Za-z0-9 ]', \"\")\n",
        "        # Lemmatize all the words\n",
        "        tweet = \" \".join([Word(word).lemmatize() for word in tweet.split()])\n",
        "        refined_tweets.append(tweet)\n",
        "    return refined_tweets"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_Wy3CBb-Vx-"
      },
      "source": [
        "X = remove_unnecessary_data_from([tweet for tweet in tweets['text']])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CyN-Con_eXq"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, tweets.label, test_size=0.2, random_state = 42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr-EP55N3P9n"
      },
      "source": [
        "val_len = len(x_test)//2\n",
        "x_val = x_test[:val_len]\n",
        "y_val = y_test[:val_len]\n",
        "x_test = x_test[val_len:]\n",
        "y_test = y_test[val_len:]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWZ--fZ1_hAk",
        "outputId": "57ae2234-acfc-473c-e59c-a40f6af2b4e8"
      },
      "source": [
        "logreg = Pipeline([('vect', CountVectorizer()),\n",
        "                ('tfidf', TfidfTransformer()),\n",
        "                ('clf', LogisticRegression(n_jobs=1, C=1e5)),\n",
        "               ])\n",
        "logreg.fit(x_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
              "                ('clf', LogisticRegression(C=100000.0, n_jobs=1))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7VaBDNP_jaZ",
        "outputId": "afc797dc-dbbb-47cd-9de3-f5ccfe940a62"
      },
      "source": [
        "y_pred = logreg.predict(x_val)\n",
        "\n",
        "print('accuracy %s' % accuracy_score(y_pred, y_val))\n",
        "print(classification_report(y_val, y_pred, digits=5))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy 0.9955022488755623\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99127   1.00000   0.99561       681\n",
            "           1    1.00000   0.99081   0.99538       653\n",
            "\n",
            "    accuracy                        0.99550      1334\n",
            "   macro avg    0.99563   0.99541   0.99550      1334\n",
            "weighted avg    0.99554   0.99550   0.99550      1334\n",
            "\n"
          ]
        }
      ]
    }
  ]
}